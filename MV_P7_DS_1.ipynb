{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86994a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aec0cb",
   "metadata": {},
   "source": [
    "# Pr√©paration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51181a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test = pd.read_csv(r'application_test.csv')\n",
    "print('Testing data shape: ', app_test.shape)\n",
    "app_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fa100",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv(r'application_train.csv')\n",
    "print('Training data shape: ', app_train.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd914e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train['TARGET'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032325e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train['TARGET'].astype(int).plot.hist();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f0b5c4",
   "metadata": {},
   "source": [
    "On a un fort d√©s√©quilibre entre les classes dans le jeu de donn√©es, les valeurs 1 sont beaucoup plus rares quue les 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns\n",
    "\n",
    "missing_values = missing_values_table(app_train)\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of each type of column\n",
    "app_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique classes in each object column\n",
    "app_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babbb642",
   "metadata": {},
   "source": [
    "## Encoding des variables cat√©gorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9624e3",
   "metadata": {},
   "source": [
    "Label encoding qui associe chaque cat√©gorie √† un chiffre arbitraire pour les variables qui n'ont que deux cat√©gories et OneHot encoding pour les variables qui ont plus de deux cat√©gories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b09db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform both training and testing data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc18b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_test = pd.get_dummies(app_test)\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be552ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "\n",
    "# Add the target back in\n",
    "app_train['TARGET'] = train_labels\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839168d",
   "metadata": {},
   "source": [
    "Le jeu de donn√©es de train et de test ont maintenant les m√™mes dimensions, ce qui est requis pour faire du machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b3803",
   "metadata": {},
   "source": [
    "# Analyses exploratoires des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(app_train['DAYS_BIRTH'] / -365).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44d2e0",
   "metadata": {},
   "source": [
    "Il ne semble pas y avoir d'√¢ge abh√©rrant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train['DAYS_EMPLOYED'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fcbfdd",
   "metadata": {},
   "source": [
    "L√† il y a un probl√®me car les valeurs maximum sont bien trop grandes pour √™tre r√©alistes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\n",
    "plt.xlabel('Days Employment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse approfondie des valeurs anormales de la variable DAYS_EMPLOYED\n",
    "anom = app_train[app_train['DAYS_EMPLOYED'] == 365243]\n",
    "non_anom = app_train[app_train['DAYS_EMPLOYED'] != 365243]\n",
    "print('The non-anomalies default on %0.2f%% of loans' % (100 * non_anom['TARGET'].mean()))\n",
    "print('The anomalies default on %0.2f%% of loans' % (100 * anom['TARGET'].mean()))\n",
    "print('There are %d anomalous days of employment' % len(anom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c04ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an anomalous flag column\n",
    "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "app_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\n",
    "plt.xlabel('Days Employment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "print('Il y a %d anomalies dans le jeu de donn√©es de test parmi %d donn√©es' % (app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlations with the target and sort\n",
    "correlations = app_train.corr()['TARGET'].sort_values()\n",
    "\n",
    "# Display correlations\n",
    "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d654704",
   "metadata": {},
   "source": [
    "L'√¢ge est la plus importante corr√©lation positive, cependant cett evaleur √©tant n√©gative (jour depuis la naissance des clients par rapport au jour du pr√™t) cela signifie que plus un client est √¢g√© plus il y a de chance que le pr√™t soit rembours√© √† temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlation of the positive days since birth and target\n",
    "app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\n",
    "app_train['DAYS_BIRTH'].corr(app_train['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of plots\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Plot the distribution of ages in years\n",
    "plt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins = 25)\n",
    "plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8fe07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "\n",
    "# KDE plot of loans that were repaid on time\n",
    "sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')\n",
    "\n",
    "# KDE plot of loans which were not repaid on time\n",
    "sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')\n",
    "\n",
    "# Labeling of plot\n",
    "plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40daca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age information into a separate dataframe\n",
    "age_data = app_train[['TARGET', 'DAYS_BIRTH']]\n",
    "age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365\n",
    "\n",
    "# Bin the age data\n",
    "age_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20, 70, num = 11))\n",
    "age_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b2621",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_groups  = age_data.groupby('YEARS_BINNED').mean()\n",
    "age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dae1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "\n",
    "# Graph the age bins and the average of the target as a bar plot\n",
    "plt.bar(age_groups.index.astype(str), 100 * age_groups['TARGET'])\n",
    "\n",
    "# Plot labeling\n",
    "plt.xticks(rotation = 75); plt.xlabel('Age Group (years)'); plt.ylabel('Failure to Repay (%)')\n",
    "plt.title('Failure to Repay by Age Group');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209eb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the EXT_SOURCE variables and show correlations\n",
    "ext_data = app_train[['TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
    "ext_data_corrs = ext_data.corr()\n",
    "ext_data_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2137f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "\n",
    "# Heatmap of correlations\n",
    "sns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\n",
    "plt.title('Correlation Heatmap');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d6714",
   "metadata": {},
   "source": [
    "L'√¢ge est fortement corr√©l√©e √† la variable \"External_source_1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a77278",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 12))\n",
    "\n",
    "# iterate through the sources\n",
    "for i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']):\n",
    "    \n",
    "    # create a new subplot for each source\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    # plot repaid loans\n",
    "    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, source], label = 'target == 0')\n",
    "    # plot loans that were not repaid\n",
    "    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, source], label = 'target == 1')\n",
    "    \n",
    "    # Label the plots\n",
    "    plt.title('Distribution of %s by Target Value' % source)\n",
    "    plt.xlabel('%s' % source); plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout(h_pad = 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data for plotting\n",
    "plot_data = ext_data.drop(columns = ['DAYS_BIRTH']).copy()\n",
    "\n",
    "# Add in the age of the client in years\n",
    "plot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']\n",
    "\n",
    "# Drop na values and limit to first 100000 rows\n",
    "plot_data = plot_data.dropna().loc[:100000, :]\n",
    "\n",
    "# Function to calculate correlation coefficient between two columns\n",
    "def corr_func(x, y, **kwargs):\n",
    "    r = np.corrcoef(x, y)[0][1]\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.2, .8), xycoords=ax.transAxes,\n",
    "                size = 20)\n",
    "\n",
    "# Create the pairgrid object\n",
    "grid = sns.PairGrid(data = plot_data, height = 3, diag_sharey=False,\n",
    "                    hue = 'TARGET', \n",
    "                    vars = [x for x in list(plot_data.columns) if x != 'TARGET'])\n",
    "\n",
    "# Upper is a scatter plot\n",
    "grid.map_upper(plt.scatter, alpha = 0.2)\n",
    "\n",
    "# Diagonal is a histogram\n",
    "grid.map_diag(sns.kdeplot)\n",
    "\n",
    "# Bottom is density plot\n",
    "grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);\n",
    "\n",
    "plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e52b8f",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(df_path, num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv(df_path, nrows= num_rows)\n",
    "    # test_df = pd.read_csv('application_test.csv', nrows= num_rows)\n",
    "    print(\"Dataframe lengh: {}\".format(len(df)))\n",
    "    # df = pd.concat([df, test_df], ignore_index=True)\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    # del test_df\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('bureau_balance.csv', nrows = num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('previous_application.csv', nrows = num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n",
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = pd.read_csv('POS_CASH_balance.csv', nrows = num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg\n",
    "    \n",
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('installments_payments.csv', nrows = num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = pd.read_csv('credit_card_balance.csv', nrows = num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_feature_engineering(df_path, debug = False):\n",
    "    # Si debug=True, on ne charge que 10000 lignes pour tester vite\n",
    "    num_rows = 10000 if debug else None\n",
    "    \n",
    "    # 1. On pr√©pare la table principale\n",
    "    print(\"Processing application train/test...\")\n",
    "    df = application_train_test(df_path, num_rows)\n",
    "    print(\"Main table shape:\", df.shape)\n",
    "    \n",
    "    # 2. On traite 'bureau' et on FUSIONNE (Left Join) sur SK_ID_CURR\n",
    "    print(\"Processing bureau...\")\n",
    "    bureau = bureau_and_balance(num_rows)\n",
    "    df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "    del bureau; gc.collect() # Important pour lib√©rer la m√©moire\n",
    "    \n",
    "    # 3. Idem pour les demandes pr√©c√©dentes\n",
    "    print(\"Processing previous applications...\")\n",
    "    prev = previous_applications(num_rows)\n",
    "    df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "    del prev; gc.collect()\n",
    "    \n",
    "    # 4. Idem pour POS_CASH\n",
    "    print(\"Processing POS-CASH balance...\")\n",
    "    pos = pos_cash(num_rows)\n",
    "    df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "    del pos; gc.collect()\n",
    "    \n",
    "    # 5. Idem pour les paiements √©chelonn√©s\n",
    "    print(\"Processing installments payments...\")\n",
    "    ins = installments_payments(num_rows)\n",
    "    df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "    del ins; gc.collect()\n",
    "    \n",
    "    # 6. Idem pour les cartes de cr√©dit\n",
    "    print(\"Processing credit card balance...\")\n",
    "    cc = credit_card_balance(num_rows)\n",
    "    df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "    del cc; gc.collect()\n",
    "    \n",
    "    print(\"Final DataFrame shape:\", df.shape)\n",
    "    # On retourne le gros DataFrame final, pr√™t pour le Machine Learning\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application de tout ce processus\n",
    "train_df = run_full_feature_engineering(df_path = \"application_train.csv\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95043c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application de tout ce processus\n",
    "test_df = run_full_feature_engineering(df_path = \"application_test.csv\", debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763e4c2",
   "metadata": {},
   "source": [
    "# Test d'apr√®s la page MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f741e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_experiment(\"MLflow Quickstart\")\n",
    "\n",
    "# # Load the Iris dataset\n",
    "# X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # Define the model hyperparameters\n",
    "# params = {\n",
    "#     \"solver\": \"lbfgs\",\n",
    "#     \"max_iter\": 1000,\n",
    "#     \"multi_class\": \"auto\",\n",
    "#     \"random_state\": 8888,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enable autologging for scikit-learn\n",
    "# mlflow.sklearn.autolog()\n",
    "\n",
    "# # Just train the model normally\n",
    "# lr = LogisticRegression(**params)\n",
    "# lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2423a8",
   "metadata": {},
   "source": [
    "### Pour log le mod√®le manuellement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start an MLflow run\n",
    "# with mlflow.start_run():\n",
    "#     # Log the hyperparameters\n",
    "#     mlflow.log_params(params)\n",
    "\n",
    "#     # Train the model\n",
    "#     lr = LogisticRegression(**params)\n",
    "#     lr.fit(X_train, y_train)\n",
    "\n",
    "#     # Log the model\n",
    "#     model_info = mlflow.sklearn.log_model(sk_model=lr, name=\"iris_model\")\n",
    "\n",
    "#     # Predict on the test set, compute and log the loss metric\n",
    "#     y_pred = lr.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "#     # Optional: Set a tag that we can use to remind ourselves what this run was for\n",
    "#     mlflow.set_tag(\"Training Info\", \"Basic LR model for iris data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df186aa4",
   "metadata": {},
   "source": [
    "### Pour r√©cup√©rer le mod√®le dpeuis MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model back for predictions as a generic Python Function model\n",
    "# loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "# predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "# result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "# result[\"actual_class\"] = y_test\n",
    "# result[\"predicted_class\"] = predictions\n",
    "\n",
    "# result[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0779b29",
   "metadata": {},
   "source": [
    "# Initialisation de l'environnment MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c82944",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Elaboration du mod√®le de scoring - P7 DS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5da1d",
   "metadata": {},
   "source": [
    "# Test de diff√©rents mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24982b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57506aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_complet = train_df['TARGET']\n",
    "X_complet = train_df.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_complet, y_complet, test_size=0.2, random_state=42, stratify=y_complet\n",
    ")\n",
    "\n",
    "print(f\"Taille du jeu d'entra√Ænement complet : {X_complet.shape}\")\n",
    "print(f\"Taille du nouveau jeu d'entra√Ænement : {X_train.shape}\")\n",
    "print(f\"Taille du jeu de validation : {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "print(\"Shape de X_train :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_grid(model):\n",
    "    name = model.__class__.__name__  #pour trouver le type de mod√®le, permet √† la fonction d'√™tre dynamique et de l'utiliser pour plusieurs types de mod√®les\n",
    "    grids = {\n",
    "        \"LogisticRegression\": {\n",
    "            'model__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'model__penalty': ['l1', 'l2'],\n",
    "            'model__solver': ['liblinear']\n",
    "        },\n",
    "        \"RandomForestClassifier\": {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__max_depth': [5, 10, None],\n",
    "            'model__class_weight': ['balanced', None] #pour g√©rer le d√©s√©quilibre des classes\n",
    "        },\n",
    "        \"XGBClassifier\": {\n",
    "            'model__n_estimators': [50, 100, 200],\n",
    "            'model__max_depth': [2, 3, 6],\n",
    "            'model__scale_pos_weight': [1, 10], #pour g√©rer le d√©s√©quilibre des classes\n",
    "            'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "            'model__random_state': [42],\n",
    "            'model__use_label_encoder': [False], # Pour √©viter un warning\n",
    "            'model__eval_metric': ['logloss']\n",
    "        }         \n",
    "    }\n",
    "\n",
    "    return grids.get(name, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a560b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mise en place de la pipeline pour faire le preprocessing et la mise en place du mod√®le\n",
    "def pipeline_model(model_type, X_train, y_train, X_val, y_val):\n",
    "    model_name = model_type.__class__.__name__\n",
    "    with mlflow.start_run(run_name=f\"GS_{model_name}\", nested=True) as child_run:\n",
    "        steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')), #g√®re les NaN\n",
    "            ('scaler', StandardScaler()), #standardisation des donn√©es\n",
    "            ('model', model_type)                        \n",
    "        ]\n",
    "\n",
    "        pipeline=Pipeline(steps=steps)\n",
    "\n",
    "        param_grid = get_param_grid(model_type)\n",
    "        \n",
    "        print(f\"Hyperparam√®tres pour {model_name} : {param_grid}\")\n",
    "        \n",
    "        mlflow.set_tag(\"model_type\", model_name)\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"GS_{model_name}\")\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        grid_search_model = GridSearchCV(pipeline, param_grid, cv=cv, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "        grid_search_model.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred__dumb = grid_search_model.predict_proba(X_val)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val, y_val_pred__dumb)\n",
    "        print(f\"Score AUC sur validation : {val_auc:.4f}\")\n",
    "        #Tracer de la courbe ROC\n",
    "        fpr, tpr, thresholds = roc_curve(y_val, y_val_pred__dumb)\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'Mod√®le (AUC = {val_auc:.3f})')\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Hasard')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('Taux de Faux Positifs')\n",
    "        ax.set_ylabel('Taux de Vrais Positifs')\n",
    "        ax.set_title(f'Courbe ROC - Mod√®le {model_name}')\n",
    "        ax.legend(loc=\"lower right\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    return grid_search_model, val_auc, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96565074",
   "metadata": {},
   "source": [
    "## Mod√®le de base - Dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efa14c",
   "metadata": {},
   "source": [
    "C'est le mod√®le de base qui va nous servir √† comparer les mod√®les que nous allons tester. En effet, si leur performances sont √©quivalentes voire inf√©rieures √† celui-ci alors ces mod√®les ne seront pas √† retenir pour r√©pondre au client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a541187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be224a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_model = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Dummy Model\"):\n",
    "    dumb_model.fit(X_train, y_train)\n",
    "    y_val_pred__dumb = dumb_model.predict_proba(X_val)[:, 1]\n",
    "    val_auc = roc_auc_score(y_val, y_val_pred__dumb)\n",
    "    print(f\"Score AUC sur validation : {val_auc:.4f}\")\n",
    "    #Tracer de la courbe ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred__dumb)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'Mod√®le (AUC = {val_auc:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Hasard')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('Taux de Faux Positifs')\n",
    "    ax.set_ylabel('Taux de Vrais Positifs')\n",
    "    ax.set_title('Courbe ROC - Mod√®le Dummy')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.grid(True)\n",
    "    mlflow.log_figure(fig, \"roc_curve_dumb.png\")\n",
    "    plt.close(fig)\n",
    "    #Enregistrement du mod√®le dans MLflow\n",
    "    mlflow.sklearn.log_model(dumb_model, \"dummy_model\")\n",
    "    mlflow.log_param(\"strategy\", \"most_frequent\")\n",
    "    mlflow.log_metric(\"auc_score\", val_auc)\n",
    "    print(\"Run MLFlow termin√©.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d0e9fb",
   "metadata": {},
   "source": [
    "## R√©gression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, auc_lr, fig_lr = pipeline_model(LogisticRegression(), X_train, y_train, X_val, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc1a36",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d708869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, auc_rf, fig_rf = pipeline_model(RandomForestClassifier(), X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93152136",
   "metadata": {},
   "source": [
    "## Mod√®le XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37168608",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb, auc_xgb, fig_xgb = pipeline_model(XGBClassifier(), X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b435198",
   "metadata": {},
   "source": [
    "# Mod√®le LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ef48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f70bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset_for_lgbm(df):\n",
    "    # S√©lectionne les colonnes qui sont de type 'object' (texte)\n",
    "    obj_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    if len(obj_cols) > 0:\n",
    "        print(f\"‚ö†Ô∏è Correction de {len(obj_cols)} colonnes de type 'object'...\")\n",
    "        for col in obj_cols:\n",
    "            # On force la conversion en num√©rique. \n",
    "            # Les erreurs (texte qui n'est pas un nombre) deviennent NaN\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    print(\"‚úÖ Types de donn√©es nettoy√©s. Pr√™t pour LightGBM.\")\n",
    "    return df\n",
    "\n",
    "# Applique le nettoyage sur tes jeux de donn√©es\n",
    "X_train = clean_dataset_for_lgbm(X_train)\n",
    "X_val = clean_dataset_for_lgbm(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e33c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_names(df):\n",
    "    # Remplace tous les caract√®res \"interdits\" par un underscore\n",
    "    # On garde seulement les lettres, chiffres et l'underscore\n",
    "    new_cols = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
    "    \n",
    "    # On assigne les nouveaux noms\n",
    "    df.columns = new_cols\n",
    "    print(\"‚úÖ Noms de colonnes nettoy√©s pour LightGBM.\")\n",
    "    return df\n",
    "\n",
    "# --- APPLIQUE √áA AVANT TON GRIDSEARCH ---\n",
    "X_train = clean_feature_names(X_train)\n",
    "X_val = clean_feature_names(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465298d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_lightgbm_with_early_stopping(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    # 1. On d√©finit le mod√®le de base (sans hyperparam√®tres fix√©s, sauf le n_jobs)\n",
    "    lgbm = lgb.LGBMClassifier(random_state=42, n_jobs=1) # n_jobs=1 pour laisser le GridSearch g√©rer les c≈ìurs\n",
    "\n",
    "    # 2. La grille de param√®tres √† tester\n",
    "    # Note : On ne met pas de \"model__\" devant car il n'y a plus de pipeline !\n",
    "    param_grid ={\n",
    "            'n_estimators': [100, 500, 1000],\n",
    "            'learning_rate': [0.02, 0.05],\n",
    "            'num_leaves': [34, 50],\n",
    "            'colsample_bytree': [0.7, 0.9],\n",
    "            'subsample': [0.8, 1],\n",
    "            'max_depth': [8, -1],\n",
    "            'scale_pos_weight': [1, 10], #pour g√©rer le d√©s√©quilibre des classes\n",
    "            'random_state': [42],\n",
    "            'n_jobs': [1]\n",
    "        }\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) # 3 folds pour aller plus vite\n",
    "        \n",
    "    grid = GridSearchCV(\n",
    "        estimator=lgbm,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='roc_auc',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    print(\"üöÄ Lancement du GridSearch avec Early Stopping...\")\n",
    "        \n",
    "    grid.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],        # Le jeu de validation pour l'early stopping\n",
    "        eval_metric='auc',                # La m√©trique √† surveiller\n",
    "        callbacks=[                       # Les callbacks LightGBM\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(period=0)  # period=0 pour ne pas spammer la console √† chaque essai\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Meilleur score AUC (interne CV) : {grid.best_score_:.4f}\")\n",
    "    print(f\"‚úÖ Meilleurs param√®tres : {grid.best_params_}\")\n",
    "    \n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgbmmodel = grid_search_lightgbm_with_early_stopping(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe74bc",
   "metadata": {},
   "source": [
    "# Calcule du score m√©tier et du seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfb12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce12751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_score_metier(y_true, y_pred):\n",
    "    # 1. Extraction des valeurs de la matrice de confusion\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    score = (10 * fn) + fp\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae757a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metier = make_scorer(calcul_score_metier, greater_is_better=False)\n",
    "score_metier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109564b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_model_score(model_type, X_train, y_train, X_val, y_val):\n",
    "    model_name = model_type.__class__.__name__\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"GS_{model_name}\", nested=True) as child_run:\n",
    "        steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model_type)                        \n",
    "        ]\n",
    "\n",
    "        pipeline = Pipeline(steps=steps)\n",
    "        param_grid = get_param_grid(model_type)\n",
    "        \n",
    "        print(f\"Hyperparam√®tres pour {model_name} : {param_grid}\")\n",
    "        \n",
    "        mlflow.set_tag(\"model_type\", model_name)\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"GS_{model_name}\")\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        grid_search_model = GridSearchCV(\n",
    "            pipeline, \n",
    "            param_grid, \n",
    "            cv=cv, \n",
    "            scoring=score_metier, # <--- C'est ici que la magie op√®re\n",
    "            verbose=1, \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        grid_search_model.fit(X_train, y_train)\n",
    "        \n",
    "        # --- LOGGING DU MEILLEUR SCORE ---\n",
    "        # Attention : comme greater_is_better=False, ce score sera n√©gatif (ex: -150)\n",
    "        # On prend la valeur absolue pour l'affichage si on veut\n",
    "        best_cost = abs(grid_search_model.best_score_)\n",
    "        print(f\"Meilleur co√ªt m√©tier moyen sur le CV : {best_cost:.2f}\")\n",
    "        mlflow.log_metric(\"best_cv_business_cost\", best_cost) # <--- On loggue √ßa dans MLflow\n",
    "\n",
    "        # --- EVALUATION SUR VAL ---\n",
    "        # 1. Calcul de l'AUC (on garde √ßa, c'est utile)\n",
    "        y_val_probs = grid_search_model.predict_proba(X_val)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val, y_val_probs)\n",
    "        \n",
    "        # 2. Calcul du CO√õT R√âEL sur la validation (NOUVEAU)\n",
    "        y_val_pred = grid_search_model.predict(X_val) # Pr√©dictions dures (0 ou 1)\n",
    "        val_cost = calcul_score_metier(y_val, y_val_pred) # On utilise ta fonction directement\n",
    "        \n",
    "        print(f\"Score AUC sur validation : {val_auc:.4f}\")\n",
    "        print(f\"Co√ªt M√©tier sur validation : {val_cost} ‚Ç¨\") # <--- Affichage important\n",
    "        \n",
    "        mlflow.log_metric(\"val_auc\", val_auc)\n",
    "        mlflow.log_metric(\"val_business_cost\", val_cost)\n",
    "\n",
    "        # --- TRAC√â ROC (INCHANG√â) ---\n",
    "        fpr, tpr, thresholds = roc_curve(y_val, y_val_probs)\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'Mod√®le (AUC = {val_auc:.3f})')\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Hasard')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('Taux de Faux Positifs')\n",
    "        ax.set_ylabel('Taux de Vrais Positifs')\n",
    "        ax.set_title(f'Courbe ROC - Mod√®le {model_name}')\n",
    "        ax.legend(loc=\"lower right\")\n",
    "        ax.grid(True)\n",
    "        \n",
    "        # Log de la figure dans MLflow\n",
    "        mlflow.log_figure(fig, f\"roc_curve_{model_name}.png\")\n",
    "\n",
    "    return grid_search_model, val_auc, fig, val_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238dba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_lightgbm_with_early_stopping_score(X_train, y_train, X_val, y_val):\n",
    "    model_name = \"LGBMClassifier\"\n",
    "    with mlflow.start_run(run_name=f\"GS_{model_name}\", nested=True) as child_run:\n",
    "        preprocessor = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        X_train_proc = preprocessor.fit_transform(X_train)\n",
    "        X_val_proc = preprocessor.transform(X_val)\n",
    "    \n",
    "    # 1. On d√©finit le mod√®le de base (sans hyperparam√®tres fix√©s, sauf le n_jobs)\n",
    "        lgbm = lgb.LGBMClassifier(random_state=42, n_jobs=1) # n_jobs=1 pour laisser le GridSearch g√©rer les c≈ìurs\n",
    "\n",
    "    # 2. La grille de param√®tres √† tester\n",
    "    # Note : On ne met pas de \"model__\" devant car il n'y a plus de pipeline !\n",
    "        param_grid ={\n",
    "                'n_estimators': [100, 500, 1000],\n",
    "                'learning_rate': [0.02, 0.05],\n",
    "                'num_leaves': [34, 50],\n",
    "                'colsample_bytree': [0.7, 0.9],\n",
    "                'subsample': [0.8, 1],\n",
    "                'max_depth': [8, -1],\n",
    "                'class_weight': [None, 'balanced'], #pour g√©rer le d√©s√©quilibre des classes\n",
    "                'random_state': [42],\n",
    "                'n_jobs': [1]\n",
    "            }\n",
    "        \n",
    "        mlflow.set_tag(\"model_type\", model_name)\n",
    "        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) # 3 folds pour aller plus vite\n",
    "            \n",
    "        grid = GridSearchCV(\n",
    "            estimator=lgbm,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring=score_metier,\n",
    "            verbose=1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        print(\"üöÄ Lancement du GridSearch avec Early Stopping...\")\n",
    "            \n",
    "        grid.fit(\n",
    "            X_train_proc, y_train,\n",
    "            eval_set=[(X_val_proc, y_val)],        # Le jeu de validation pour l'early stopping\n",
    "            eval_metric='auc', #mieux que le score directement car mon score n'est pas une variable continue\n",
    "            callbacks=[                       # Les callbacks LightGBM\n",
    "                lgb.early_stopping(stopping_rounds=100),\n",
    "                lgb.log_evaluation(period=0)  # period=0 pour ne pas spammer la console √† chaque essai\n",
    "            ]\n",
    "        )\n",
    "        best_cost = abs(grid.best_score_) #car le score retourner est n√©gatif avec greater_is_better=False\n",
    "        print(f\"Meilleur co√ªt m√©tier moyen sur le CV : {best_cost:.2f}\")\n",
    "        mlflow.log_metric(\"best_cv_business_cost\", best_cost) # <--- On loggue √ßa dans MLflow\n",
    "\n",
    "        mlflow.log_params(grid.best_params_)\n",
    "        y_val_pred = grid.predict(X_val_proc) # Pr√©dictions dures (0 ou 1)\n",
    "        y_val_probs = grid.predict_proba(X_val_proc)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val, y_val_probs)\n",
    "        # On calcule le co√ªt r√©el sur la validation\n",
    "        real_cost_val = calcul_score_metier(y_val, y_val_pred)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y_val, y_val_probs)\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'Mod√®le (AUC = {val_auc:.3f})')\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Hasard')\n",
    "        ax.set_title(f'Courbe ROC - Mod√®le {model_name}')\n",
    "        ax.legend(loc=\"lower right\")\n",
    "        \n",
    "        mlflow.log_figure(fig, f\"roc_curve_{model_name}.png\")\n",
    "\n",
    "        print(f\"‚úÖ Meilleur score score m√©tier (CV) : {grid.best_score_:.4f}\")\n",
    "        print(f\"‚úÖ Meilleurs param√®tres : {grid.best_params_}\")\n",
    "        \n",
    "        return grid.best_estimator_, val_auc, fig, real_cost_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc083fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgbmmodel, lgbm_auc, lgbm_score, fig_lgbm = grid_search_lightgbm_with_early_stopping_score(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [LogisticRegression(), RandomForestClassifier(), XGBClassifier()]\n",
    "\n",
    "score_model_df = pd.DataFrame(columns=[\"Mod√®le\", \"AUC\", \"Score m√©tier\"])\n",
    "for model in models_list:\n",
    "    grid_search_model, val_auc, fig, val_cost = pipeline_model_score(model, X_train, y_train, X_val, y_val)\n",
    "    score_model_df = pd.concat([score_model_df, pd.DataFrame([{\n",
    "        \"Mod√®le\": model.__class__.__name__,\n",
    "        \"AUC\": val_auc,\n",
    "        \"Score m√©tier\": val_cost\n",
    "    }])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91bd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model_df = pd.concat([score_model_df, pd.DataFrame([{\n",
    "        \"Mod√®le\": \"LightGBM\",\n",
    "        \"AUC\": lgbm_auc,\n",
    "        \"Score m√©tier\": lgbm_score\n",
    "    }])], ignore_index=True)\n",
    "print(score_model_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P7_OC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
